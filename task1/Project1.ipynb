{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import xgboost as xgb \n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>14168.823171</td>\n",
       "      <td>10514.380717</td>\n",
       "      <td>3316.149698</td>\n",
       "      <td>94230.695124</td>\n",
       "      <td>102.386606</td>\n",
       "      <td>92.677127</td>\n",
       "      <td>11108.748199</td>\n",
       "      <td>10866.505510</td>\n",
       "      <td>10837.622093</td>\n",
       "      <td>10.227734</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12352.094085</td>\n",
       "      <td>846.014651</td>\n",
       "      <td>105.132144</td>\n",
       "      <td>102.112809</td>\n",
       "      <td>2090.004260</td>\n",
       "      <td>2.691845</td>\n",
       "      <td>1234.374109</td>\n",
       "      <td>1000.784475</td>\n",
       "      <td>9285.751272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17757.037554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4101.016273</td>\n",
       "      <td>92959.527633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.855168</td>\n",
       "      <td>10013.959449</td>\n",
       "      <td>10826.607494</td>\n",
       "      <td>10076.101597</td>\n",
       "      <td>11.436970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16198.071494</td>\n",
       "      <td>776.084467</td>\n",
       "      <td>106.385590</td>\n",
       "      <td>103.472030</td>\n",
       "      <td>2474.051881</td>\n",
       "      <td>2.287976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.626705</td>\n",
       "      <td>11750.284764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>14226.656663</td>\n",
       "      <td>11029.642499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124055.600561</td>\n",
       "      <td>100.542483</td>\n",
       "      <td>92.860892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10492.342868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.810076</td>\n",
       "      <td>...</td>\n",
       "      <td>10329.704431</td>\n",
       "      <td>13976.063780</td>\n",
       "      <td>737.040332</td>\n",
       "      <td>103.671234</td>\n",
       "      <td>109.458246</td>\n",
       "      <td>2656.083281</td>\n",
       "      <td>2.843706</td>\n",
       "      <td>888.353607</td>\n",
       "      <td>1048.810385</td>\n",
       "      <td>9553.922728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>8766.012436</td>\n",
       "      <td>7384.202998</td>\n",
       "      <td>2147.308418</td>\n",
       "      <td>100157.719990</td>\n",
       "      <td>104.855061</td>\n",
       "      <td>101.929026</td>\n",
       "      <td>10050.049932</td>\n",
       "      <td>10499.521099</td>\n",
       "      <td>10525.030989</td>\n",
       "      <td>10.092109</td>\n",
       "      <td>...</td>\n",
       "      <td>10008.251395</td>\n",
       "      <td>6212.127347</td>\n",
       "      <td>329.044233</td>\n",
       "      <td>105.084488</td>\n",
       "      <td>104.858546</td>\n",
       "      <td>1097.785204</td>\n",
       "      <td>2.732257</td>\n",
       "      <td>927.752967</td>\n",
       "      <td>1048.357330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>13801.016418</td>\n",
       "      <td>13269.493652</td>\n",
       "      <td>3408.316953</td>\n",
       "      <td>92048.527786</td>\n",
       "      <td>103.759758</td>\n",
       "      <td>95.789235</td>\n",
       "      <td>9667.353978</td>\n",
       "      <td>10750.783106</td>\n",
       "      <td>10618.800750</td>\n",
       "      <td>12.006773</td>\n",
       "      <td>...</td>\n",
       "      <td>10095.782015</td>\n",
       "      <td>13772.061493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.369834</td>\n",
       "      <td>2693.053231</td>\n",
       "      <td>2.702908</td>\n",
       "      <td>1471.354073</td>\n",
       "      <td>1071.284484</td>\n",
       "      <td>9423.533063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x0            x1           x2             x3          x4  \\\n",
       "id                                                                        \n",
       "0.0  14168.823171  10514.380717  3316.149698   94230.695124  102.386606   \n",
       "1.0  17757.037554           NaN  4101.016273   92959.527633         NaN   \n",
       "2.0  14226.656663  11029.642499          NaN  124055.600561  100.542483   \n",
       "3.0   8766.012436   7384.202998  2147.308418  100157.719990  104.855061   \n",
       "4.0  13801.016418  13269.493652  3408.316953   92048.527786  103.759758   \n",
       "\n",
       "             x5            x6            x7            x8         x9  ...  \\\n",
       "id                                                                    ...   \n",
       "0.0   92.677127  11108.748199  10866.505510  10837.622093  10.227734  ...   \n",
       "1.0   99.855168  10013.959449  10826.607494  10076.101597  11.436970  ...   \n",
       "2.0   92.860892           NaN  10492.342868           NaN  10.810076  ...   \n",
       "3.0  101.929026  10050.049932  10499.521099  10525.030989  10.092109  ...   \n",
       "4.0   95.789235   9667.353978  10750.783106  10618.800750  12.006773  ...   \n",
       "\n",
       "             x822          x823        x824        x825        x826  \\\n",
       "id                                                                    \n",
       "0.0           NaN  12352.094085  846.014651  105.132144  102.112809   \n",
       "1.0           NaN  16198.071494  776.084467  106.385590  103.472030   \n",
       "2.0  10329.704431  13976.063780  737.040332  103.671234  109.458246   \n",
       "3.0  10008.251395   6212.127347  329.044233  105.084488  104.858546   \n",
       "4.0  10095.782015  13772.061493         NaN         NaN  100.369834   \n",
       "\n",
       "            x827      x828         x829         x830          x831  \n",
       "id                                                                  \n",
       "0.0  2090.004260  2.691845  1234.374109  1000.784475   9285.751272  \n",
       "1.0  2474.051881  2.287976          NaN  1012.626705  11750.284764  \n",
       "2.0  2656.083281  2.843706   888.353607  1048.810385   9553.922728  \n",
       "3.0  1097.785204  2.732257   927.752967  1048.357330           NaN  \n",
       "4.0  2693.053231  2.702908  1471.354073  1071.284484   9423.533063  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"X_train.csv\",\n",
    "                delimiter=',',\n",
    "                index_col = 'id')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y\n",
       "id       \n",
       "0.0  74.0\n",
       "1.0  51.0\n",
       "2.0  70.0\n",
       "3.0  52.0\n",
       "4.0  85.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(\"y_train.csv\",\n",
    "                delimiter=',',\n",
    "                index_col='id')\n",
    "# y = pd.Series(y).reset_index()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#we use knn\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "X_imp = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stdised = sklearn.preprocessing.StandardScaler().fit(X_imp).transform(X_imp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Selection/Dimensity reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA reduction of dimensions\n",
    "pca = sklearn.decomposition.PCA(n_components=554, random_state=42)\n",
    "X_reduced = pca.fit_transform(X_stdised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umap reduction\n",
    "import umap\n",
    "\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "X_reduced = reducer.fit(digits.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_Never(n_estimators, max_depth, sampling_method, reg_alpha, reg_lambda):\n",
    "  regressor_xgb = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, sampling_method=sampling_method, reg_alpha=reg_alpha*0.1, reg_lambda=reg_lambda*0.1, random_state=42)\n",
    "  regressor_xgb.fit(X_reduced, y)\n",
    "  print('XGB (train): ' + str(r2_score(y, regressor_xgb.predict(X_reduced))))\n",
    "\n",
    "  return r2_score(y, regressor_xgb.predict(X_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB (train): 0.9617109710178833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[14:06:29] /workspace/src/tree/hist/sampler.h:51: Check failed: param.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\nStack trace:\n  [bt] (0) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x7001aa) [0x7fc28ae031aa]\n  [bt] (1) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x74a9b7) [0x7fc28ae4d9b7]\n  [bt] (2) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x460609) [0x7fc28ab63609]\n  [bt] (3) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x4610fc) [0x7fc28ab640fc]\n  [bt] (4) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x4c4e87) [0x7fc28abc7e87]\n  [bt] (5) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fc28a864d60]\n  [bt] (6) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(+0x9056) [0x7fc30e624056]\n  [bt] (7) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(+0x7ae9) [0x7fc30e622ae9]\n  [bt] (8) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(ffi_call+0x123) [0x7fc30e623353]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sophiesd/AML/task1/Project1.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m params \u001b[39m=\u001b[39m ng\u001b[39m.\u001b[39mp\u001b[39m.\u001b[39mInstrumentation(n_estimators, max_depth, sampling_method, reg_alpha, reg_lambda)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer \u001b[39m=\u001b[39m ng\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mTwoPointsDE(parametrization\u001b[39m=\u001b[39mparams, budget\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m bestX \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mminimize(XGB_Never, batch_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/nevergrad/optimization/base.py:678\u001b[0m, in \u001b[0;36mOptimizer.minimize\u001b[0;34m(self, objective_function, executor, batch_mode, verbosity, constraint_violation)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finished_jobs:\n\u001b[1;32m    677\u001b[0m     x, job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finished_jobs[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m     result \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m constraint_violation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell(\n\u001b[1;32m    681\u001b[0m             x, result, [f(x\u001b[39m.\u001b[39mvalue) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m constraint_violation]\n\u001b[1;32m    682\u001b[0m         )  \u001b[39m# TODO: this is not parallelized, wtf!\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/nevergrad/optimization/utils.py:137\u001b[0m, in \u001b[0;36mDelayedJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tp\u001b[39m.\u001b[39mAny:\n\u001b[1;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed:\n\u001b[0;32m--> 137\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "\u001b[1;32m/home/sophiesd/AML/task1/Project1.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mXGB_Never\u001b[39m(n_estimators, max_depth, sampling_method, reg_alpha, reg_lambda):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m   regressor_xgb \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(n_estimators\u001b[39m=\u001b[39mn_estimators, max_depth\u001b[39m=\u001b[39mmax_depth, sampling_method\u001b[39m=\u001b[39msampling_method, reg_alpha\u001b[39m=\u001b[39mreg_alpha\u001b[39m*\u001b[39m\u001b[39m0.1\u001b[39m, reg_lambda\u001b[39m=\u001b[39mreg_lambda\u001b[39m*\u001b[39m\u001b[39m0.1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m   regressor_xgb\u001b[39m.\u001b[39;49mfit(X_reduced, y)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mXGB (train): \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(r2_score(y, regressor_xgb\u001b[39m.\u001b[39mpredict(X_reduced))))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sophiesd/AML/task1/Project1.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m r2_score(y, regressor_xgb\u001b[39m.\u001b[39mpredict(X_reduced))\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m (\n\u001b[1;32m   1078\u001b[0m     model,\n\u001b[1;32m   1079\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1085\u001b[0m )\n\u001b[0;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1087\u001b[0m     params,\n\u001b[1;32m   1088\u001b[0m     train_dmatrix,\n\u001b[1;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1098\u001b[0m )\n\u001b[1;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/core.py:2049\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2049\u001b[0m     _check_call(\n\u001b[1;32m   2050\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2051\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2052\u001b[0m         )\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/core.py:281\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [14:06:29] /workspace/src/tree/hist/sampler.h:51: Check failed: param.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\nStack trace:\n  [bt] (0) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x7001aa) [0x7fc28ae031aa]\n  [bt] (1) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x74a9b7) [0x7fc28ae4d9b7]\n  [bt] (2) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x460609) [0x7fc28ab63609]\n  [bt] (3) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x4610fc) [0x7fc28ab640fc]\n  [bt] (4) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(+0x4c4e87) [0x7fc28abc7e87]\n  [bt] (5) /home/linuxbrew/.linuxbrew/Cellar/python@3.11/3.11.5/lib/python3.11/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fc28a864d60]\n  [bt] (6) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(+0x9056) [0x7fc30e624056]\n  [bt] (7) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(+0x7ae9) [0x7fc30e622ae9]\n  [bt] (8) /home/linuxbrew/.linuxbrew/opt/libffi/lib/libffi.so.8(ffi_call+0x123) [0x7fc30e623353]\n\n"
     ]
    }
   ],
   "source": [
    "import nevergrad as ng\n",
    "\n",
    "\n",
    "n_estimators = ng.p.TransitionChoice(range(1,101))\n",
    "\n",
    "#start = 0.1\n",
    "#stop = 0.7\n",
    "#step = 0.01\n",
    "#float_range = [x / 100 for x in range(int(start * 100), int(stop * 100), int(step * 100))]\n",
    "\n",
    "\n",
    "#eta = ng.p.TransitionChoice(float_range) # eta\n",
    "#print(eta)\n",
    "max_depth = ng.p.TransitionChoice(range(4,11))\n",
    "sampling_method = ng.p.Choice(['uniform', 'gradient_based'])\n",
    "reg_alpha =  ng.p.TransitionChoice(range(0,10, 1))\n",
    "reg_lambda =  ng.p.TransitionChoice(range(0,10, 1))\n",
    "\n",
    "params = ng.p.Instrumentation(n_estimators, max_depth, sampling_method, reg_alpha, reg_lambda)\n",
    "optimizer = ng.optimizers.TwoPointsDE(parametrization=params, budget=10000)\n",
    "bestX = optimizer.minimize(XGB_Never, batch_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestX.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
